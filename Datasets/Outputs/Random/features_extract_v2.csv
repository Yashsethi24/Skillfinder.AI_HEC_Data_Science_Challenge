,demand_id,extracted_text,translated_text,extracted_features
0,Scrum,"scrum master – contrat de 12 mois lieu : montréal date de démarrage : dès que possible durée : 12 mois, avec possibilité de renouvellement dans le cadre d’un mandat d’importance stratégique, nous recherchons un(e) scrum master expérimenté(e) pour guider une équipe agile multidisciplinaire au sein d’un environnement stimulant et en pleine transformation numérique. nom de l’entreprise : alimora groupe slogan : cultiver l’avenir, nourrir l’excellence présentation de l’entreprise : fondé en 1998, alimora groupe est un acteur majeur de l’agroalimentaire durable en amérique du nord. spécialisé dans la production, la transformation et la distribution de produits alimentaires de qualité, le groupe s'engage à offrir une alimentation saine et accessible, tout en respectant l’environnement et les communautés locales. avec plus de 1 500 employés répartis sur 7 sites de production et une présence dans plus de 12 pays, alimora se distingue par son innovation constante, son excellence opérationnelle et sa capacité à anticiper les tendances de consommation. domaines d’expertise : • transformation de produits frais (fruits, légumes, protéines végétales) • production bio et circuits courts • recherche & développement en nutrition durable • logistique intégrée et chaîne du froid • développement de produits à marque privée (mdd) rôle et responsabilités en tant que scrum master, vous jouerez un rôle clé dans le pilotage de l’agilité opérationnelle d’une équipe, en favorisant l’atteinte des objectifs d’affaires tout en renforçant la collaboration, la transparence et l’amélioration continue. vos responsabilités incluent notamment : • mettre en place et maintenir un cadre agile efficace propice à la performance collective. • faciliter l’ensemble des cérémonies scrum (daily scrum, sprint planning, sprint review, rétrospective, refinement). • assurer une gestion proactive des obstacles, afin de garantir le bon déroulement des livrables. • accompagner l’équipe dans le développement de son autonomie et de sa capacité d’auto-organisation. • agir en tant que coach agile, en guidant l’équipe et les parties prenantes dans la compréhension et l’application des valeurs, principes et pratiques agiles. • promouvoir une culture de collaboration et d’amélioration continue. • aider le product owner à gérer efficacement le backlog produit, à définir les priorités et à maximiser la valeur livrée. • mesurer et analyser la performance de l’équipe via des indicateurs clés (vélocité, burndown charts, lead time, etc.), en utilisant des outils adaptés. • protéger l’équipe des interférences externes et veiller à maintenir un climat de travail serein. environnement technologique et outils utilisés • outils de gestion agile : jira, confluence • communication et collaboration : microsoft teams, slack, miro • tableaux de bord et métriques : jira dashboards, power bi, excel avancé • méthodologies : scrum, kanban, safe (atout), lean • langues : français (essentiel), anglais (fonctionnel) profil recherché • minimum 3 ans d’expérience en tant que scrum master dans un contexte agile à fort enjeu. • solide compréhension des cadres méthodologiques agiles (scrum, kanban, lean) et capacité à adapter les pratiques au contexte de l’équipe. • excellentes compétences interpersonnelles : leadership, diplomatie, capacité d’influence. • fort esprit d’analyse et capacité à traduire les problématiques en actions concrètes. • expérience dans un contexte hybride ou multi-équipes est un atout. ce mandat vous permettra de contribuer activement à la réussite d’une équipe agile engagée, tout en évoluant dans un environnement propice à la transformation numérique et à l'innovation.","Scrum Master - 12 -month contract Place: Montreal Start date: As soon as possible Duration: 12 months, with the possibility of renewal as part of a mandate of strategic importance, we are looking for an experienced scrum master to guide an agile multidisciplinary team within a stimulating environment and in full digital transformation. Company name: Alimora Slogan Group: Cultivate the future, nourishing the excellence of the company: Founded in 1998, Alimora Groupe is a major player in the sustainable food industry in North America. Specializing in the production, processing and distribution of quality food products, the group undertakes to offer a healthy and accessible food, while respecting the environment and local communities. With more than 1,500 employees spread over 7 production sites and a presence in more than 12 countries, Alimora is distinguished by its constant innovation, its operational excellence and its ability to anticipate consumption trends. Domains of expertise: • Transformation of fresh products (fruits, vegetables, vegetable proteins) • Organic production and short circuits • Research & development in sustainable nutrition • Integrated logistics and cold of cold products (MDD) Role and responsibilities as scrum master, you will play a key role in the management of the operational agility of a team, promoting the achievement of business objectives while reinforcing collaboration, transparency and continuous improvement. Your responsibilities include in particular: • Set up and maintain an efficient framework conducive to collective performance. • Facilitate all Scrum ceremonies (Daily Scrum, Sprint Planning, Sprint Review, Retrospective, Refinement). • Ensure proactive management of obstacles, in order to guarantee the smooth running of deliverables. • Support the team in the development of its autonomy and its self-organization capacity. • Act as an agile coach, guiding the team and the stakeholders in the understanding and application of agile values, principles and practices. • Promote a culture of collaboration and continuous improvement. • Help the product Owner effectively manages the product backlog, defining priorities and maximizing the delivered value. • Measure and analyze the performance of the team via key indicators (velocity, burndown charts, lead time, etc.), using suitable tools. • Protect the external interference team and ensure that you maintain a serene working climate. Technological environment and tools used • Agile management tools: JIRA, Confluence • Communication and collaboration: Microsoft Teams, Slack, Miro • Dashboards and metrics: Jira Dashboards, Power Bi, Excel Advanced • Methodologies: Scrum, Kanban, Safe (Atout), Lean • Languages: French (essential), English (functional) that Scrum Master in an agile context at high stake. • Solid understanding of agile methodological frameworks (Scrum, Kanban, Lean) and ability to adapt practices to the context of the team. • Excellent interpersonal skills: leadership, diplomacy, ability to influence. • Strong spirit of analysis and ability to translate issues into concrete actions. • Experience in a hybrid or multi-team context is an asset. This mandate will allow you to actively contribute to the success of an agile committed team, while evolving in an environment conducive to digital transformation and innovation.","{'Job Title': 'Scrum Master', 'Required Skills': [{'skill': 'Agile operational agility', 'level': 3}, {'skill': 'Scrum ceremonies facilitation', 'level': 3}, {'skill': 'Obstacle management', 'level': 3}, {'skill': 'Agile coaching', 'level': 3}, {'skill': 'Collaboration and continuous improvement', 'level': 3}, {'skill': 'Backlog management', 'level': 3}, {'skill': 'Performance measurement and analysis', 'level': 3}, {'skill': 'External interference protection', 'level': 3}], 'Preferred Skills': [{'skill': 'Hybrid or multi-team experience', 'level': 2}], 'Experience Required': 3.0, 'Languages': [{'language': 'French', 'level': 3}, {'language': 'English', 'level': 2}], 'Responsibilities': ['Establish and maintain an effective agile framework for collective performance.', 'Facilitate all scrum ceremonies (daily scrum, sprint planning, sprint review, retrospective, refinement).', 'Proactively manage obstacles to ensure smooth delivery.', 'Support the team in developing autonomy and self-organization.', 'Act as an agile coach, guiding the team and stakeholders in understanding and applying agile values, principles, and practices.', 'Promote a culture of collaboration and continuous improvement.', 'Assist the product owner in effectively managing the product backlog, defining priorities, and maximizing delivered value.', 'Measure and analyze team performance using key indicators (velocity, burndown charts, lead time, etc.) with appropriate tools.', 'Protect the team from external interference and maintain a peaceful working environment.'], 'Location': 'Montreal', 'Salary': '', 'Additional Notes': {'Duration': '12 months', 'Type': 'Contract', 'Mode of work': 'On-site'}}"
1,Data Engineer,"poste : data engineer • type de contrat : contrat • date de début : dès que possible • durée du mandat : 12 mois • date limite de dépôt : 6 novembre à 14h à propos de l’entreprise : retailnova est un leader du secteur du commerce de détail, avec un réseau de distribution omnicanal présent à travers tout le territoire. l'entreprise combine innovation technologique et excellence opérationnelle pour optimiser ses processus, anticiper les besoins des clients et maximiser la performance. dans le cadre de sa stratégie de transformation numérique, retailnova investit massivement dans la modernisation de ses infrastructures de données pour accélérer la prise de décision fondée sur des analyses avancées. contexte du mandat : retailnova met en œuvre une nouvelle plateforme d'entreprise basée sur des technologies cloud afin de centraliser, sécuriser et valoriser ses données opérationnelles, transactionnelles et clients. ce projet stratégique vise à moderniser l'écosystème analytique, à automatiser les flux de données, à améliorer la gouvernance, et à renforcer la qualité et la traçabilité des données à l’échelle de l’entreprise. le data engineer sera responsable de la conception, du développement, de l’optimisation et du déploiement des pipelines de données nécessaires à l’alimentation du data lake d’entreprise. il interviendra également dans la mise en place de nouvelles architectures de traitement en temps réel, en assurant la robustesse, la scalabilité et la performance des solutions déployées. responsabilités détaillées : • concevoir et développer des pipelines d’ingestion de données robustes et optimisés à l’aide d’azure data factory pour intégrer des données provenant de sources multiples (erp, crm, pos, e-commerce, etc.). • développer des transformations complexes en utilisant apache spark (scala/python) dans azure databricks, avec une forte orientation performance et optimisation des coûts. • implémenter des flux de données streaming et batch via databricks streaming et apache kafka, en assurant une faible latence et une haute disponibilité. • participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques (data marts, data lakehouse). • mettre en œuvre des processus de validation de la qualité des données (data quality checks, data profiling, monitoring automatisé). • automatiser les déploiements et les tests des pipelines via azure devops (ci/cd, versioning, rollback). • documenter les solutions développées selon les normes internes, et assurer la traçabilité et la réplicabilité des traitements. • travailler en collaboration avec les équipes data science, bi et it infrastructure pour garantir l’alignement des livrables avec les objectifs stratégiques. • participer à l’élaboration de normes et de standards d’ingénierie des données à l’échelle de l’organisation. compétences techniques requises : • 5+ ans d'expérience en développement d’applications de traitement de données distribuées avec apache spark (obligatoire). • solide maîtrise de python et scala pour le développement de traitements de données volumineuses. • expérience significative avec azure data factory, azure data lake storage (gen2), et azure databricks. • connaissance approfondie de kafka (installation, configuration, gestion des topics, sécurité, monitoring). • maîtrise des principes d’architecture data : partitionnement, indexation, optimisation des formats (parquet, delta lake), gestion des métadonnées. • expérience avec les outils de gestion des flux ci/cd dans azure devops (pipelines, artefacts, gestion de configuration). • connaissance des principes de gouvernance des données, de catalogage (ex. azure purview), et des bonnes pratiques de sécurité (rbac, encryption, masking). • capacité à concevoir des modèles de données analytiques (kimball, data vault) et à travailler avec des entrepôts de données (ex. synapse analytics). atouts : • expérience dans des environnements retail ou grande distribution (gestion des données transactionnelles, gestion de la supply chain, etc.). • expérience avec des outils de monitoring des pipelines (ex : azure monitor, log analytics, datadog). • connaissances de base en data science/machine learning pour interagir avec les équipes concernées. compétences interpersonnelles : • forte capacité à résoudre des problèmes complexes de manière autonome. • rigueur et attention aux détails, particulièrement dans les aspects liés à la qualité et la fiabilité des données. • compétences en communication technique, capacité à documenter et présenter des solutions techniques à divers niveaux d’interlocuteurs. • esprit d’équipe, ouverture au partage de connaissances et participation active à l’amélioration continue. langues : • français et anglais : maîtrise professionnelle complète, tant à l’oral qu’à l’écrit.","poste : data engineer • type de contrat : contrat • date de début : dès que possible • durée du mandat : 12 mois • date limite de dépôt : 6 novembre à 14h à propos de l’entreprise : retailnova est un leader du secteur du commerce de détail, avec un réseau de distribution omnicanal présent à travers tout le territoire. l'entreprise combine innovation technologique et excellence opérationnelle pour optimiser ses processus, anticiper les besoins des clients et maximiser la performance. dans le cadre de sa stratégie de transformation numérique, retailnova investit massivement dans la modernisation de ses infrastructures de données pour accélérer la prise de décision fondée sur des analyses avancées. contexte du mandat : retailnova met en œuvre une nouvelle plateforme d'entreprise basée sur des technologies cloud afin de centraliser, sécuriser et valoriser ses données opérationnelles, transactionnelles et clients. ce projet stratégique vise à moderniser l'écosystème analytique, à automatiser les flux de données, à améliorer la gouvernance, et à renforcer la qualité et la traçabilité des données à l’échelle de l’entreprise. le data engineer sera responsable de la conception, du développement, de l’optimisation et du déploiement des pipelines de données nécessaires à l’alimentation du data lake d’entreprise. il interviendra également dans la mise en place de nouvelles architectures de traitement en temps réel, en assurant la robustesse, la scalabilité et la performance des solutions déployées. responsabilités détaillées : • concevoir et développer des pipelines d’ingestion de données robustes et optimisés à l’aide d’azure data factory pour intégrer des données provenant de sources multiples (erp, crm, pos, e-commerce, etc.). • développer des transformations complexes en utilisant apache spark (scala/python) dans azure databricks, avec une forte orientation performance et optimisation des coûts. • implémenter des flux de données streaming et batch via databricks streaming et apache kafka, en assurant une faible latence et une haute disponibilité. • participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques (data marts, data lakehouse). • mettre en œuvre des processus de validation de la qualité des données (data quality checks, data profiling, monitoring automatisé). • automatiser les déploiements et les tests des pipelines via azure devops (ci/cd, versioning, rollback). • documenter les solutions développées selon les normes internes, et assurer la traçabilité et la réplicabilité des traitements. • travailler en collaboration avec les équipes data science, bi et it infrastructure pour garantir l’alignement des livrables avec les objectifs stratégiques. • participer à l’élaboration de normes et de standards d’ingénierie des données à l’échelle de l’organisation. compétences techniques requises : • 5+ ans d'expérience en développement d’applications de traitement de données distribuées avec apache spark (obligatoire). • solide maîtrise de python et scala pour le développement de traitements de données volumineuses. • expérience significative avec azure data factory, azure data lake storage (gen2), et azure databricks. • connaissance approfondie de kafka (installation, configuration, gestion des topics, sécurité, monitoring). • maîtrise des principes d’architecture data : partitionnement, indexation, optimisation des formats (parquet, delta lake), gestion des métadonnées. • expérience avec les outils de gestion des flux ci/cd dans azure devops (pipelines, artefacts, gestion de configuration). • connaissance des principes de gouvernance des données, de catalogage (ex. azure purview), et des bonnes pratiques de sécurité (rbac, encryption, masking). • capacité à concevoir des modèles de données analytiques (kimball, data vault) et à travailler avec des entrepôts de données (ex. synapse analytics). atouts : • expérience dans des environnements retail ou grande distribution (gestion des données transactionnelles, gestion de la supply chain, etc.). • expérience avec des outils de monitoring des pipelines (ex : azure monitor, log analytics, datadog). • connaissances de base en data science/machine learning pour interagir avec les équipes concernées. compétences interpersonnelles : • forte capacité à résoudre des problèmes complexes de manière autonome. • rigueur et attention aux détails, particulièrement dans les aspects liés à la qualité et la fiabilité des données. • compétences en communication technique, capacité à documenter et présenter des solutions techniques à divers niveaux d’interlocuteurs. • esprit d’équipe, ouverture au partage de connaissances et participation active à l’amélioration continue. langues : • français et anglais : maîtrise professionnelle complète, tant à l’oral qu’à l’écrit.","{'Job Title': 'Data Engineer', 'Required Skills': [{'skill': 'Apache Spark', 'level': 3}, {'skill': 'Python', 'level': 3}, {'skill': 'Scala', 'level': 3}, {'skill': 'Azure Data Factory', 'level': 2}, {'skill': 'Azure Data Lake Storage (Gen2)', 'level': 2}, {'skill': 'Azure Databricks', 'level': 2}, {'skill': 'Kafka', 'level': 2}, {'skill': 'Data architecture principles', 'level': 2}, {'skill': 'Azure DevOps', 'level': 2}, {'skill': 'Data governance principles', 'level': 2}, {'skill': 'Data modeling', 'level': 2}, {'skill': 'Data warehousing', 'level': 2}], 'Preferred Skills': [{'skill': 'Retail or supply chain data management', 'level': 1}, {'skill': 'Pipeline monitoring tools (e.g., Azure Monitor, Log Analytics, Datadog)', 'level': 1}, {'skill': 'Basic knowledge of data science/machine learning', 'level': 1}], 'Experience Required': 5.0, 'Languages': [{'language': 'French', 'level': 3}, {'language': 'English', 'level': 3}], 'Responsibilities': ['Design and develop robust and optimized data ingestion pipelines using Azure Data Factory', 'Develop complex transformations using Apache Spark (Scala/Python) in Azure Databricks', 'Implement streaming and batch data flows using Databricks Streaming and Apache Kafka', 'Define and implement data models for analytical needs (data marts, data lakehouse)', 'Implement data quality validation processes (data quality checks, data profiling, automated monitoring)', 'Automate pipeline deployments and testing using Azure DevOps', 'Document developed solutions according to internal standards and ensure traceability and replicability', 'Collaborate with data science, BI, and IT infrastructure teams to align deliverables with strategic objectives', 'Participate in the development of data engineering standards and best practices'], 'Location': '', 'Salary': '', 'Additional Notes': {'Duration': '12 months', 'Type': 'Contract', 'Mode of work': 'Full-time'}}"
2,Data Analyst,"profil data analyst – marketing analytics à propos de veltrixia veltrixia technologies inc. est une entreprise spécialisée dans les solutions de données et l'intelligence marketing. basée à montréal, veltrixia accompagne depuis plus de 15 ans des entreprises nord-américaines dans l’optimisation de leurs performances grâce à des technologies analytiques avancées. l’entreprise mise sur l’innovation, la collaboration et l’excellence pour propulser ses clients vers le futur numérique. contexte dans le cadre du développement de notre équipe analytique marketing, nous recherchons un·e analyste de données pour travailler sur des projets liés à la collecte, l’analyse et la visualisation de données marketing. vous serez responsable de la maintenance et de l’évolution de jeux de données provenant de sources variées, afin de soutenir les équipes dans leur prise de décision basée sur les données. détails du poste • durée : 10 mois (renouvelable) • type : temps plein • mode de travail : hybride (2 jours par semaine au bureau à montréal) responsabilités principales • gérer et améliorer les jeux de données marketing. • développer des tableaux de bord et rapports dans power bi. • optimiser les performances des datasets power bi. • intégrer les données issues de diverses plateformes (google analytics, crm, outils marketing). • rédiger du code sql, dax et power query performant. • collaborer étroitement avec les analystes pour comprendre leurs besoins. • créer des requêtes dans databricks et ssms. • assurer la qualité et la fiabilité des données. • soutenir les collègues via des revues de code et du support technique. • concevoir des modèles de données adaptés aux objectifs métiers. profil recherché compétences techniques • minimum 5 ans d’expérience en analyse de données. • solide maîtrise de sql (ms sql server), power bi, databricks. • expérience avec dax, power query, etl. • connaissance des données marketing, un atout. • capacité à modéliser les données et à optimiser les processus. compétences personnelles • curieux·se, autonome, rigoureux·se. • bonne gestion du temps et esprit d’équipe. • excellente capacité d’analyse et de résolution de problèmes. langues • maîtrise de l’anglais et du français.","Profile Data Analyst - Marketing Analytics about Veltrixia Veltrixia Technologies inc. is a company specializing in data solutions and marketing intelligence. Based in Montreal, Veltrixia has been supporting North American companies for more than 15 years in optimizing their performance through advanced analytical technologies. The company relies on innovation, collaboration and excellence to propel its customers to the future digital. Context within the framework of the development of our analytical marketing team, we are looking for an analyst of data to work on projects related to the collection, analysis and visualization of marketing data. You will be responsible for the maintenance and evolution of datasets from various sources, in order to support the teams in their data -based decision -making. Details of the position • Duration: 10 months (renewable) • Type: full time • Work mode: hybrid (2 days per week at the office in Montreal) main responsibilities • Manage and improve marketing data games. • Develop dashboards and reports in Power Bi. • Optimize the performance of Power Bi datasets. • Integrate data from various platforms (Google Analytics, CRM, Marketing Tools). • Write SQL, Dax and powerful power query code. • Collaborate closely with analysts to understand their needs. • Create requests in Databricks and SSMS. • Ensure the quality and reliability of the data. • Support colleagues via code journals and technical support. • Design data models adapted to business objectives. Profile sought technical skills • minimum 5 years of experience in data analysis. • Solid mastery of SQL (MS SQL Server), Power Bi, Databricks. • Experience with Dax, Power Query, etl. • Knowledge of marketing data, an asset. • Ability to model data and optimize processes. Personal skills • Curious, autonomous, rigorous. • Good time management and team spirit. • Excellent analytical and problem solving capacity. Languages ​​• Mastery of English and French.","{'Job Title': 'Data Analyst - Marketing Analytics', 'Required Skills': [{'skill': 'SQL (MS SQL Server)', 'level': 2}, {'skill': 'Power BI', 'level': 2}, {'skill': 'Databricks', 'level': 2}, {'skill': 'DAX', 'level': 2}, {'skill': 'Power Query', 'level': 2}, {'skill': 'ETL', 'level': 2}, {'skill': 'Data Analysis', 'level': 2}], 'Preferred Skills': [{'skill': 'Marketing Data', 'level': 1}], 'Experience Required': 5.0, 'Languages': [{'language': 'English', 'level': 3}, {'language': 'French', 'level': 3}], 'Responsibilities': ['Manage and improve marketing datasets.', 'Develop dashboards and reports in Power BI.', 'Optimize performance of Power BI datasets.', 'Integrate data from various platforms (Google Analytics, CRM, marketing tools).', 'Write efficient SQL, DAX, and Power Query code.', 'Collaborate closely with analysts to understand their needs.', 'Create queries in Databricks and SSMS.', 'Ensure data quality and reliability.', 'Support colleagues through code reviews and technical support.', 'Design data models aligned with business objectives.'], 'Location': 'Montreal', 'Salary': '', 'Additional Notes': {'Duration': '10 months (renewable)', 'Type': 'Full-time', 'Mode of work': 'Hybrid (2 days per week in the office in Montreal)'}}"
