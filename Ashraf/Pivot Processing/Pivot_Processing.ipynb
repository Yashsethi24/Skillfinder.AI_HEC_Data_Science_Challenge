{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 95606,
          "databundleVersionId": 11453440,
          "sourceType": "competition"
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV files into DataFrames\n",
        "df_lang = pd.read_csv('/content/HCK_HEC_LANG.csv')\n",
        "df_skills = pd.read_csv('/content/HCK_HEC_SKILLS.csv')\n",
        "df_staffing = pd.read_csv('/content/HCK_HEC_STAFFING.csv')\n",
        "df_user = pd.read_csv('/content/HCK_HEC_USER.csv')\n",
        "df_xp = pd.read_csv('/content/HCK_HEC_XP.csv')"
      ],
      "metadata": {
        "id": "zOGS9To0o1Gg"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to pivot tables"
      ],
      "metadata": {
        "id": "dMyT8M9P6w-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def pivot_skills_table(df_skills: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Pivot the skills table to ensure all skills are included, even if no current user has them.\n",
        "    \"\"\"\n",
        "    # Step 1: Get all unique skills\n",
        "    all_skills = df_skills[\"SKILLS_DSC\"].unique()\n",
        "\n",
        "    # Step 2: Create dummy rows with a fake user to ensure all skills appear\n",
        "    dummy_user_id = -99999\n",
        "    dummy_rows = pd.DataFrame({\n",
        "        \"USER_ID\": [dummy_user_id] * len(all_skills),\n",
        "        \"SKILLS_DSC\": all_skills,\n",
        "        \"LEVEL_VAL\": [0] * len(all_skills)\n",
        "    })\n",
        "\n",
        "    # Step 3: Append dummy to original skills table\n",
        "    df_skills_augmented = pd.concat([df_skills, dummy_rows], ignore_index=True)\n",
        "\n",
        "    # Step 4: Pivot\n",
        "    skills_pivot = df_skills_augmented.pivot_table(\n",
        "        index=\"USER_ID\",\n",
        "        columns=\"SKILLS_DSC\",\n",
        "        values=\"LEVEL_VAL\",\n",
        "        aggfunc='max',\n",
        "        fill_value=0\n",
        "    )\n",
        "\n",
        "    # Step 5: Drop the dummy user and rename columns\n",
        "    skills_pivot = skills_pivot.drop(index=dummy_user_id)\n",
        "    skills_pivot.columns = [f\"{col}_level\" for col in skills_pivot.columns]\n",
        "\n",
        "    return skills_pivot.reset_index()\n",
        "\n",
        "def pivot_language_table(df_lang: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Pivot the language table to ensure English and French columns are always included,\n",
        "    even if no users currently have those language scores.\n",
        "    \"\"\"\n",
        "    # Define the languages you want to ensure are always present\n",
        "    required_languages = [\"English\", \"French\"]\n",
        "\n",
        "    # Step 1: Create dummy rows for each language\n",
        "    dummy_user_id = -99999\n",
        "    dummy_rows = pd.DataFrame({\n",
        "        \"USER_ID\": [dummy_user_id] * len(required_languages),\n",
        "        \"LANGUAGE_SKILL_DSC\": required_languages,\n",
        "        \"LANGUAGE_SKILL_LVL\": [0] * len(required_languages)\n",
        "    })\n",
        "\n",
        "    # Step 2: Append dummy to original lang table\n",
        "    df_lang_augmented = pd.concat([df_lang, dummy_rows], ignore_index=True)\n",
        "\n",
        "    # Step 3: Pivot\n",
        "    lang_pivot = df_lang_augmented.pivot_table(\n",
        "        index=\"USER_ID\",\n",
        "        columns=\"LANGUAGE_SKILL_DSC\",\n",
        "        values=\"LANGUAGE_SKILL_LVL\",\n",
        "        aggfunc='max',\n",
        "        fill_value=0\n",
        "    )\n",
        "\n",
        "    # Step 4: Drop the dummy user and rename columns\n",
        "    lang_pivot = lang_pivot.drop(index=dummy_user_id, errors='ignore')\n",
        "    lang_pivot = lang_pivot.rename(columns={\n",
        "        \"English\": \"English_level\",\n",
        "        \"French\": \"French_level\"\n",
        "    })\n",
        "\n",
        "    return lang_pivot.reset_index()\n",
        "\n",
        "\n",
        "def merge_user_skills_languages(\n",
        "    df_user: pd.DataFrame,\n",
        "    skills_pivot: pd.DataFrame,\n",
        "    lang_pivot: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Merges the user base table with pivoted skills and language tables.\n",
        "    Fills missing values with 0.\n",
        "    \"\"\"\n",
        "    merged_df = df_user.merge(skills_pivot, on=\"USER_ID\", how=\"left\")\n",
        "    merged_df = merged_df.merge(lang_pivot, on=\"USER_ID\", how=\"left\")\n",
        "    merged_df.fillna(0, inplace=True)\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "skills_pivoted = pivot_skills_table(df_skills)\n",
        "lang_pivoted = pivot_language_table(df_lang)\n",
        "Users_Lang_Skills = merge_user_skills_languages(df_user, skills_pivoted, lang_pivoted)"
      ],
      "metadata": {
        "id": "8dMcRRW-Aed7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Users_Lang_Skills DataFrame as a CSV file\n",
        "lang_pivoted.to_csv(\"lang_pivoted.csv\", index=False)\n",
        "skills_pivoted.to_csv(\"skills_pivoted.csv\", index=False)\n",
        "Users_Lang_Skills.to_csv(\"Users_Lang_Skills.csv\", index=False)"
      ],
      "metadata": {
        "id": "SJHfQq_67X_3"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}