{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RpNob7ZzaGAE"
      ]
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 95606,
          "databundleVersionId": 11453440,
          "sourceType": "competition"
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV files into DataFrames\n",
        "skills_pivoted = pd.read_csv('/content/skills_pivoted.csv')\n",
        "Users_Lang_Skills = pd.read_csv('/content/Users_Lang_Skills.csv')\n",
        "staffing_inverted = pd.read_csv('/content/staffing_inverted.csv')"
      ],
      "metadata": {
        "id": "zOGS9To0o1Gg",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I6yFUXrFLXlm",
        "outputId": "8720d08b-0c8c-4555-9755-c74d7808960a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fuzzy Wuzzy Matching"
      ],
      "metadata": {
        "id": "B6pwVDHnQYif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "def prepare_required_skill_mapping(selected_job: str, known_skills: list, threshold: int = 90) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Prepares the required skill mapping for a job and stores it in the global `mapping` variable.\n",
        "    Also returns a DataFrame of Extracted Skill → Matched Skill for reference.\n",
        "\n",
        "    Parameters:\n",
        "        selected_job (str): The job title (e.g., \"Data Engineer\")\n",
        "        known_skills (list): A list of standardized known skills (e.g., from skills_pivoted.columns)\n",
        "        threshold (int): Fuzzy matching threshold (default: 90)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame of Extracted Skill and Matched Skill\n",
        "    \"\"\"\n",
        "    global mapping\n",
        "\n",
        "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            parsed = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"No JSON file found for selected job: {file_path}\")\n",
        "\n",
        "    required_skills = parsed.get(\"Required Skills\", [])\n",
        "    if not required_skills:\n",
        "        print(f\"⚠️ No 'Required Skills' found in JSON for {selected_job}\")\n",
        "        mapping = {}\n",
        "        return pd.DataFrame(columns=[\"Extracted Skill\", \"Matched Skill\"])\n",
        "\n",
        "    # Standardize skill names\n",
        "    def standardize_skill_name(name):\n",
        "        return name.lower().strip().replace(\"-\", \" \").replace(\"_\", \" \")\n",
        "\n",
        "    extracted_skills_std = [standardize_skill_name(skill) for skill in required_skills]\n",
        "\n",
        "    # Perform fuzzy matching\n",
        "    mapping = {}\n",
        "    for skill in extracted_skills_std:\n",
        "        match_result = process.extractOne(skill, known_skills)\n",
        "        if match_result:\n",
        "            matched_name, score = match_result\n",
        "            if score >= threshold:\n",
        "                mapping[skill] = matched_name\n",
        "\n",
        "    return pd.DataFrame(list(mapping.items()), columns=[\"Extracted Skill\", \"Matched Skill\"])\n"
      ],
      "metadata": {
        "id": "j5VTHLMYb8G1"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting matched skills scores"
      ],
      "metadata": {
        "id": "3rvf8ZGlH2zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_extracted_skill_scores_to_users() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Creates a new DataFrame with USER_ID, LAST_NAME, and Req_<matched_skill>_score columns\n",
        "    based on the mapping dict. Each score is taken from the matched skill's _level column.\n",
        "    NaNs are filled with 0.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A compact DataFrame with only USER_ID, LAST_NAME, and required skill scores.\n",
        "    \"\"\"\n",
        "    base_cols = [\"USER_ID\", \"LAST_NAME\"]\n",
        "    df = Users_Lang_Skills[base_cols].copy()\n",
        "\n",
        "    for extracted_skill, matched_skill in mapping.items():\n",
        "        matched_col = f\"{matched_skill}_level\"\n",
        "        new_score_col = f\"Req_{matched_skill}_score\"\n",
        "\n",
        "        if matched_col in Users_Lang_Skills.columns:\n",
        "            df[new_score_col] = Users_Lang_Skills[matched_col].fillna(0)\n",
        "        else:\n",
        "            df[new_score_col] = 0\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nuQz0C9XFEtN"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Scores"
      ],
      "metadata": {
        "id": "WCfHYatRIN4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "def add_extracted_language_scores_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds language score columns to score_df based on required languages from the job's JSON file.\n",
        "    Matches extracted languages to language level columns in Users_Lang_Skills using fuzzy matching.\n",
        "\n",
        "    Parameters:\n",
        "        score_df (pd.DataFrame): The scoring DataFrame to add new language score columns to.\n",
        "        selected_job (str): The job name used to locate the corresponding features JSON file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The updated DataFrame with new language score columns.\n",
        "    \"\"\"\n",
        "    # Load extracted features from the job-specific JSON file\n",
        "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            features = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"JSON file for '{selected_job}' not found.\")\n",
        "\n",
        "    # Extract the list of required languages from the job features\n",
        "    required_langs = features.get(\"Languages\", [])\n",
        "    if not required_langs:\n",
        "        return score_df  # No languages to process\n",
        "\n",
        "    # Clean up and standardize the extracted language names\n",
        "    extracted_langs = [lang.lower().strip() for lang in required_langs]\n",
        "\n",
        "    # Get all known language columns from Users_Lang_Skills (e.g., English_level, French_level)\n",
        "    known_langs = {\n",
        "        col.replace(\"_level\", \"\").lower(): col\n",
        "        for col in Users_Lang_Skills.columns\n",
        "        if col.endswith(\"_level\")\n",
        "    }\n",
        "\n",
        "    if not known_langs:\n",
        "        return score_df  # No known language data to match against\n",
        "\n",
        "    # Match each extracted language to a known one using fuzzy matching\n",
        "    lang_mapping = {}\n",
        "    for lang in extracted_langs:\n",
        "        match = process.extractOne(lang, known_langs.keys())\n",
        "        if match and match[1] >= 85:  # Only accept strong matches\n",
        "            lang_mapping[lang] = known_langs[match[0]]\n",
        "\n",
        "    if not lang_mapping:\n",
        "        return score_df  # No usable matches\n",
        "\n",
        "    # Add score columns to the DataFrame using values from Users_Lang_Skills\n",
        "    df = score_df.copy().set_index(\"USER_ID\")\n",
        "    user_data = Users_Lang_Skills.set_index(\"USER_ID\")\n",
        "\n",
        "    for lang_key, lang_col in lang_mapping.items():\n",
        "        score_col = f\"{lang_key}_score\"\n",
        "        df[score_col] = user_data[lang_col].reindex(df.index).fillna(0)\n",
        "\n",
        "    return df.reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "eZZe3VrZJjrl"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experience Score"
      ],
      "metadata": {
        "id": "0WIMFdefOq65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def add_extracted_experience_score_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds an 'experience_score' column to score_df based on the experience required\n",
        "    for the selected job, loaded from a JSON features file.\n",
        "\n",
        "    The scoring is binned:\n",
        "        - ≥ required + 2 years → 100\n",
        "        - > required + 2 to 4 → 70\n",
        "        - > required + 4       → 50\n",
        "        - == required          → 100\n",
        "        - < required by ≤ 2    → 50\n",
        "        - < required by 2–4    → 30\n",
        "        - < required by >4     → 10\n",
        "        - Missing experience   → 0\n",
        "    \"\"\"\n",
        "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            features = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"No JSON file found for job '{selected_job}'\")\n",
        "\n",
        "    required_exp = features.get(\"Experience Required\", 0)\n",
        "\n",
        "    df = score_df.copy()\n",
        "\n",
        "    def calculate_score(user_exp):\n",
        "        if pd.isna(user_exp):\n",
        "            return 0\n",
        "        delta = user_exp - required_exp\n",
        "        if delta >= 2:\n",
        "            return 100\n",
        "        elif 0 <= delta < 2:\n",
        "            return 100\n",
        "        elif -2 < delta < 0:\n",
        "            return 50\n",
        "        elif -4 < delta <= -2:\n",
        "            return 30\n",
        "        elif delta <= -4:\n",
        "            return 10\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    # Map score using ANNEES_XP from Users_Lang_Skills\n",
        "    experience_series = Users_Lang_Skills.set_index(\"USER_ID\")[\"ANNEES_XP\"]\n",
        "    df = df.set_index(\"USER_ID\")\n",
        "    df[\"experience_score\"] = experience_series.reindex(df.index).apply(calculate_score).fillna(0)\n",
        "\n",
        "    return df.reset_index()\n"
      ],
      "metadata": {
        "id": "cYnFae7bOsyz"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preferred Skills"
      ],
      "metadata": {
        "id": "rkzLqa6yPUrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "def add_extracted_preferred_skill_scores_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds Pref_<matched_skill>_score columns to score_df based on the preferred skills\n",
        "    extracted from a job's JSON file. Uses fuzzy matching to match extracted skills\n",
        "    to known _level columns in Users_Lang_Skills.\n",
        "\n",
        "    Parameters:\n",
        "        score_df (pd.DataFrame): Scoring DataFrame to update.\n",
        "        selected_job (str): Job title used to locate the features JSON.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with preferred skill score columns.\n",
        "    \"\"\"\n",
        "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            features = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"No JSON file found for job '{selected_job}'\")\n",
        "\n",
        "    preferred_skills = features.get(\"Preferred Skills\", [])\n",
        "    if not preferred_skills:\n",
        "        return score_df\n",
        "\n",
        "    def standardize(name):\n",
        "        return name.lower().strip().replace(\"-\", \" \").replace(\"_\", \" \")\n",
        "\n",
        "    preferred_skills_std = [standardize(skill) for skill in preferred_skills]\n",
        "\n",
        "    known_skills = {\n",
        "        col.replace(\"_level\", \"\").lower(): col\n",
        "        for col in Users_Lang_Skills.columns\n",
        "        if col.endswith(\"_level\")\n",
        "    }\n",
        "\n",
        "    if not known_skills:\n",
        "        return score_df\n",
        "\n",
        "    mapping = {}\n",
        "    for skill in preferred_skills_std:\n",
        "        match_result = process.extractOne(skill, list(known_skills.keys()))\n",
        "        if match_result and match_result[1] >= 85:\n",
        "            mapping[skill] = known_skills[match_result[0]]\n",
        "\n",
        "    if not mapping:\n",
        "        return score_df\n",
        "\n",
        "    df = score_df.copy().set_index(\"USER_ID\")\n",
        "    user_data = Users_Lang_Skills.set_index(\"USER_ID\")\n",
        "\n",
        "    for _, matched_col in mapping.items():\n",
        "        skill_name = matched_col.replace(\"_level\", \"\")\n",
        "        new_col = f\"Pref_{skill_name}_score\"\n",
        "        df[new_col] = user_data[matched_col].reindex(df.index).fillna(0)\n",
        "\n",
        "    return df.reset_index()\n"
      ],
      "metadata": {
        "id": "XEGckestPXTO"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Availability Score"
      ],
      "metadata": {
        "id": "x0LmBjeDRQ0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_availability_score_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
        "    import json\n",
        "    import re\n",
        "\n",
        "    # === Step 1: Load job features JSON ===\n",
        "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            features = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"No JSON file found for job '{selected_job}'\")\n",
        "\n",
        "    # === Step 2: Extract duration from nested 'Additional Notes' ===\n",
        "    notes_dict = features.get(\"Additional Notes\", {})\n",
        "    duration_text = str(notes_dict.get(\"Duration\", \"\"))\n",
        "    match = re.search(r\"(\\d+)\\s*month\", duration_text)\n",
        "    duration = int(match.group(1)) if match else 0\n",
        "\n",
        "    # === Step 3: Define scoring logic ===\n",
        "    def check_availability_row(row, duration):\n",
        "        values = row.tolist()\n",
        "        max_score = 0\n",
        "        for i in range(len(values) - duration + 1):\n",
        "            window = values[i:i + duration]\n",
        "            if all(v == 100 for v in window):\n",
        "                return 100, \"full block\"\n",
        "            elif 0 not in window:\n",
        "                avg = sum(window) / duration\n",
        "                max_score = max(max_score, avg)\n",
        "        return max_score, \"avg block\" if max_score > 0 else \"no block\"\n",
        "\n",
        "    # === Step 4: Score each user ===\n",
        "    scores = []\n",
        "    month_cols = [f\"MONTH_{i}\" for i in range(1, 13)]\n",
        "\n",
        "    for user_id in score_df[\"USER_ID\"]:\n",
        "        staff_row = staffing_inverted[staffing_inverted[\"USER_ID\"] == user_id]\n",
        "\n",
        "        if staff_row.empty:\n",
        "            scores.append(0)\n",
        "            continue\n",
        "\n",
        "        months = staff_row.iloc[0][month_cols]\n",
        "        score, reason = check_availability_row(months, duration)\n",
        "        scores.append(score)\n",
        "\n",
        "    # === Step 5: Merge scores into final DataFrame ===\n",
        "    result = score_df.copy()\n",
        "    result[\"availability_score\"] = scores\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "BdM3Vt7rRTew"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Trail use"
      ],
      "metadata": {
        "id": "jUc5mpaoKMFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate required skill mapping\n",
        "known_skills = [col.replace(\"_level\", \"\") for col in skills_pivoted.columns]\n",
        "\n",
        "prepare_required_skill_mapping(\"Data Engineer\", known_skills)\n",
        "\n",
        "# Start with skill scores\n",
        "score_df = add_extracted_skill_scores_to_users()\n",
        "\n",
        "# Then add language scores from JSON\n",
        "score_df = add_extracted_language_scores_to_users(score_df, selected_job=\"Data Engineer\")\n",
        "\n",
        "# Then add experience scores from JSON\n",
        "score_df = add_extracted_experience_score_to_users(score_df, selected_job=\"Data Engineer\")\n",
        "\n",
        "# Then add preferred skill scores from JSON\n",
        "score_df = add_extracted_preferred_skill_scores_to_users(score_df, \"Data Engineer\")\n",
        "\n",
        "# Then availability scores from JSON\n",
        "score_df_Data_Engineer = add_availability_score_to_users(score_df, \"Data Engineer\")"
      ],
      "metadata": {
        "id": "b6KN50lKKKmE"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_df_Data_Engineer.to_csv(\"Data_Engineer_scored.csv\", index=False)"
      ],
      "metadata": {
        "id": "s2Foi06yc_Ej"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate required skill mapping\n",
        "known_skills = [col.replace(\"_level\", \"\") for col in skills_pivoted.columns]\n",
        "\n",
        "prepare_required_skill_mapping(\"Data Analyst\", known_skills)\n",
        "\n",
        "# Start with skill scores\n",
        "score_df = add_extracted_skill_scores_to_users()\n",
        "\n",
        "# Then add language scores from JSON\n",
        "score_df = add_extracted_language_scores_to_users(score_df, selected_job=\"Data Analyst\")\n",
        "\n",
        "# Then add experience scores from JSON\n",
        "score_df = add_extracted_experience_score_to_users(score_df, selected_job=\"Data Analyst\")\n",
        "\n",
        "# Then add preferred skill scores from JSON\n",
        "score_df = add_extracted_preferred_skill_scores_to_users(score_df, \"Data Analyst\")\n",
        "\n",
        "# Then availability scores from JSON\n",
        "score_df_Data_Analyst = add_availability_score_to_users(score_df, \"Data Analyst\")"
      ],
      "metadata": {
        "id": "pn6ZoNzqcwqL"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_df_Data_Analyst.to_csv(\"Data_Analyst_scored.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "es8yPej1dBGt"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate required skill mapping\n",
        "known_skills = [col.replace(\"_level\", \"\") for col in skills_pivoted.columns]\n",
        "\n",
        "prepare_required_skill_mapping(\"Scrum Master\", known_skills)\n",
        "\n",
        "# Start with skill scores\n",
        "score_df = add_extracted_skill_scores_to_users()\n",
        "\n",
        "# Then add language scores from JSON\n",
        "score_df = add_extracted_language_scores_to_users(score_df, selected_job=\"Scrum Master\")\n",
        "\n",
        "# Then add experience scores from JSON\n",
        "score_df = add_extracted_experience_score_to_users(score_df, selected_job=\"Scrum Master\")\n",
        "\n",
        "# Then add preferred skill scores from JSON\n",
        "score_df = add_extracted_preferred_skill_scores_to_users(score_df, \"Scrum Master\")\n",
        "\n",
        "# Then availability scores from JSON\n",
        "score_df_Scrum_Master = add_availability_score_to_users(score_df, \"Scrum Master\")"
      ],
      "metadata": {
        "id": "tryH5LIMcwyD"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_df_Scrum_Master.to_csv(\"Scrum_Master_scored.csv\", index=False)"
      ],
      "metadata": {
        "id": "3NN_bre1dCvi"
      },
      "execution_count": 135,
      "outputs": []
    }
  ]
}