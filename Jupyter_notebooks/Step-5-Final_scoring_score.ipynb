{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Pivot Processing\\Output\\Users_Lang_Skills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USER_ID', 'LAST_NAME', 'FIRST_NAME', 'ANNEES_XP', 'Airbyte_level',\n",
       "       'Alteryx Analytics Hub_level', 'Alteryx Designer_level',\n",
       "       'Amazon AWS CloudFormation_level', 'Amazon AWS Glue_level',\n",
       "       'Amazon QuickSight_level',\n",
       "       ...\n",
       "       'Teradata Vantage_level', 'Terraform_level', 'VBA_level',\n",
       "       'Vena Close_level',\n",
       "       'Vena Solutions Budgeting, Planning & Forecasting_level',\n",
       "       'Workday Adaptive Planning_level', 'Workiva_level',\n",
       "       'insightsoftware Longview Planning_level', 'English_level',\n",
       "       'French_level'],\n",
       "      dtype='object', length=139)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['USER_ID','LAST_NAME','FIRST_NAME','ANNEES_XP','English_level','French_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformation to all columns except those in exclude_columns\n",
    "base_df.columns = [\n",
    "    col.replace('_level', '').lower() if col not in exclude_columns else col\n",
    "    for col in base_df.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>airbyte</th>\n",
       "      <th>alteryx analytics hub</th>\n",
       "      <th>alteryx designer</th>\n",
       "      <th>amazon aws cloudformation</th>\n",
       "      <th>amazon aws glue</th>\n",
       "      <th>amazon quicksight</th>\n",
       "      <th>...</th>\n",
       "      <th>teradata vantage</th>\n",
       "      <th>terraform</th>\n",
       "      <th>vba</th>\n",
       "      <th>vena close</th>\n",
       "      <th>vena solutions budgeting, planning &amp; forecasting</th>\n",
       "      <th>workday adaptive planning</th>\n",
       "      <th>workiva</th>\n",
       "      <th>insightsoftware longview planning</th>\n",
       "      <th>English_level</th>\n",
       "      <th>French_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  airbyte  alteryx analytics hub  \\\n",
       "0  2843838     Ramos      David        1.0      0.0                    0.0   \n",
       "1  2479537     Small       Carl        2.5      0.0                    0.0   \n",
       "2  2533337     Evans     Carmen        2.0      0.0                    0.0   \n",
       "3  2446382   Pittman     Brandi        2.5      0.0                    0.0   \n",
       "4  2433124    Thomas      Julie        2.5      0.0                    0.0   \n",
       "\n",
       "   alteryx designer  amazon aws cloudformation  amazon aws glue  \\\n",
       "0               0.0                        0.0              0.0   \n",
       "1               0.0                        0.0              0.0   \n",
       "2               0.0                        0.0              0.0   \n",
       "3               0.0                        0.0              0.0   \n",
       "4               0.0                        0.0              0.0   \n",
       "\n",
       "   amazon quicksight  ...  teradata vantage  terraform    vba  vena close  \\\n",
       "0                0.0  ...               0.0        0.0    0.0         0.0   \n",
       "1                0.0  ...               0.0        0.0  100.0         0.0   \n",
       "2                0.0  ...               0.0        0.0    0.0         0.0   \n",
       "3                0.0  ...               0.0        0.0    0.0         0.0   \n",
       "4                0.0  ...               0.0        0.0    0.0         0.0   \n",
       "\n",
       "   vena solutions budgeting, planning & forecasting  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   workday adaptive planning  workiva  insightsoftware longview planning  \\\n",
       "0                        0.0      0.0                                0.0   \n",
       "1                        0.0      0.0                                0.0   \n",
       "2                        0.0      0.0                                0.0   \n",
       "3                        0.0      0.0                                0.0   \n",
       "4                        0.0      0.0                                0.0   \n",
       "\n",
       "   English_level  French_level  \n",
       "0          100.0         100.0  \n",
       "1           90.0         100.0  \n",
       "2           50.0         100.0  \n",
       "3           60.0         100.0  \n",
       "4          100.0         100.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_job = 'Data Engineer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Mapping\\Output\\data_analyst_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the base path and job name\n",
    "base_path = r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Mapping\\Output\"\n",
    "job_name = 'data_analyst_scores'\n",
    "\n",
    "# Construct the full file path safely\n",
    "file_path = f\"{base_path}\\\\{job_name}.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "try:\n",
    "    data_analyst_df = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded data from: {file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns_1 = ['USER_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>weight_required_skills</th>\n",
       "      <th>weight_preferred_skills</th>\n",
       "      <th>weight_language</th>\n",
       "      <th>req_SQL_score</th>\n",
       "      <th>req_Microsoft Power BI_score</th>\n",
       "      <th>req_Databricks_score</th>\n",
       "      <th>req_DAX_score</th>\n",
       "      <th>req_Matillion ETL_score</th>\n",
       "      <th>lang_English_score</th>\n",
       "      <th>lang_French_score</th>\n",
       "      <th>pref_Cloudera Data Platform_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  weight_required_skills  weight_preferred_skills  weight_language  \\\n",
       "0  2843838                      13                        1                6   \n",
       "1  2479537                      13                        1                6   \n",
       "2  2533337                      13                        1                6   \n",
       "3  2446382                      13                        1                6   \n",
       "4  2433124                      13                        1                6   \n",
       "\n",
       "   req_SQL_score  req_Microsoft Power BI_score  req_Databricks_score  \\\n",
       "0          150.0                           0.0                   0.0   \n",
       "1            0.0                           0.0                   0.0   \n",
       "2          150.0                           0.0                   0.0   \n",
       "3          240.0                         240.0                   0.0   \n",
       "4            0.0                           0.0                   0.0   \n",
       "\n",
       "   req_DAX_score  req_Matillion ETL_score  lang_English_score  \\\n",
       "0            0.0                      0.0               300.0   \n",
       "1            0.0                      0.0               270.0   \n",
       "2           40.0                      0.0               150.0   \n",
       "3            0.0                      0.0               180.0   \n",
       "4            0.0                      0.0               300.0   \n",
       "\n",
       "   lang_French_score  pref_Cloudera Data Platform_score  \n",
       "0              300.0                                0.0  \n",
       "1              300.0                                0.0  \n",
       "2              300.0                                0.0  \n",
       "3              300.0                                0.0  \n",
       "4              300.0                                0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "columns = data_analyst_df.columns\n",
    "always_list = ['USER_ID']\n",
    "req_list = [col for col in columns if col.startswith('req_')] + ['weight_required_skills']\n",
    "pref_list = [col for col in columns if col.startswith('pref_')] + ['weight_preferred_skills']\n",
    "weights_list = ['weight_required_skills', 'weight_preferred_skills','weight_language']\n",
    "lang_list = [col for col in columns if col.startswith('lang_')] + ['weight_language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Language Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify all language score columns (starting with 'lang_' and ending with '_score')\n",
    "lang_score_columns = [col for col in data_analyst_df.columns \n",
    "                     if col.startswith('lang_') and col.endswith('_score')]\n",
    "\n",
    "# Step 2: Calculate normalized language score\n",
    "data_analyst_df['normalized_lang_score'] = (\n",
    "    data_analyst_df[lang_score_columns].sum(axis=1) / \n",
    "    data_analyst_df['weight_language']\n",
    ")\n",
    "\n",
    "# Optional: Round to 2 decimal places\n",
    "data_analyst_df['normalized_lang_score'] = data_analyst_df['normalized_lang_score'].round(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Required score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify all req_*_score columns\n",
    "req_score_columns = [col for col in data_analyst_df.columns \n",
    "                     if col.startswith('req_') and col.endswith('_score')]\n",
    "\n",
    "# Step 2: Sum the req_*_scores for each row and divide by weight_required_skills\n",
    "data_analyst_df['normalized_req_score'] = (\n",
    "    data_analyst_df[req_score_columns].sum(axis=1) / \n",
    "    data_analyst_df['weight_required_skills']\n",
    ")\n",
    "\n",
    "# Optional: Round the result to 2 decimal places\n",
    "data_analyst_df['normalized_req_score'] = data_analyst_df['normalized_req_score'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized preferred score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify all pref_*_score columns\n",
    "pref_score_columns = [col for col in data_analyst_df.columns \n",
    "                     if col.startswith('pref_') and col.endswith('_score')]\n",
    "\n",
    "# Step 2: Sum the pref_*_scores for each row and divide by weight_preferred_skills\n",
    "data_analyst_df['normalized_pref_score'] = (\n",
    "    data_analyst_df[pref_score_columns].sum(axis=1) / \n",
    "    data_analyst_df['weight_preferred_skills']\n",
    ")\n",
    "\n",
    "# Optional: Round the result to 2 decimal places\n",
    "data_analyst_df['normalized_pref_score'] = data_analyst_df['normalized_pref_score'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Availability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_staffing = pd.read_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Invert Months Processing\\Input\\HCK_HEC_STAFFING.csv\")  \n",
    "\n",
    "# Function to invert availability values (0 = available, 100 = unavailable)\n",
    "def invert_availability_values(staffing_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inverts the availability values in the month columns of the staffing DataFrame.\n",
    "    Converts 0 to 100 (available) and 100 to 0 (unavailable), and inverts other values proportionally.\n",
    "\n",
    "    Parameters:\n",
    "        staffing_df (pd.DataFrame): The original staffing DataFrame with month columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified staffing DataFrame with inverted availability values.\n",
    "    \"\"\"\n",
    "    # Define month columns (MONTH_1 to MONTH_12)\n",
    "    month_cols = [f\"MONTH_{i}\" for i in range(1, 13)]\n",
    "\n",
    "    # Invert values: 100 - current value for the month columns\n",
    "    staffing_inverted = staffing_df.copy()\n",
    "    staffing_inverted[month_cols] = 100 - staffing_inverted[month_cols]\n",
    "\n",
    "    return staffing_inverted\n",
    "\n",
    "# Function to save the inverted staffing DataFrame to CSV\n",
    "def save_inverted_staffing_to_csv(staffing_inverted_df: pd.DataFrame, file_name: str = \"staffing_inverted.csv\"):\n",
    "    \"\"\"\n",
    "    Saves the inverted staffing DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        staffing_inverted_df (pd.DataFrame): The modified staffing DataFrame.\n",
    "        file_name (str): The name of the file to save the CSV as.\n",
    "    \"\"\"\n",
    "    staffing_inverted_df.to_csv(file_name, index=False)\n",
    "    print(f\"Saved inverted staffing data to '{file_name}'.\")\n",
    "\n",
    "def add_availability_score_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
    "    import json\n",
    "    import re\n",
    "    import os\n",
    "    os.chdir(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Job_description_features\")\n",
    "    # === Step 1: Load job features JSON ===\n",
    "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            features = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"No JSON file found for job '{selected_job}'\")\n",
    "\n",
    "    # === Step 2: Extract duration from nested 'Additional Notes' ===\n",
    "    notes_dict = features.get(\"Additional Notes\", {})\n",
    "    duration_text = str(notes_dict.get(\"Duration\", \"\"))\n",
    "    match = re.search(r\"(\\d+)\\s*month\", duration_text)\n",
    "    duration = int(match.group(1)) if match else 0\n",
    "\n",
    "    # === Step 3: Define scoring logic ===\n",
    "    def check_availability_row(row, duration):\n",
    "        values = row.tolist()\n",
    "        max_score = 0\n",
    "        for i in range(len(values) - duration + 1):\n",
    "            window = values[i:i + duration]\n",
    "            if all(v == 100 for v in window):\n",
    "                return 100, \"full block\"\n",
    "            elif 0 not in window:\n",
    "                avg = sum(window) / duration\n",
    "                max_score = max(max_score, avg)\n",
    "        return max_score, \"avg block\" if max_score > 0 else \"no block\"\n",
    "\n",
    "    # === Step 4: Score each user ===\n",
    "    scores = []\n",
    "    month_cols = [f\"MONTH_{i}\" for i in range(1, 13)]\n",
    "\n",
    "    for user_id in score_df[\"USER_ID\"]:\n",
    "        staff_row = staffing_inverted[staffing_inverted[\"USER_ID\"] == user_id]\n",
    "\n",
    "        if staff_row.empty:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "\n",
    "        months = staff_row.iloc[0][month_cols]\n",
    "        score, reason = check_availability_row(months, duration)\n",
    "        scores.append(score)\n",
    "\n",
    "    # === Step 5: Merge scores into final DataFrame ===\n",
    "    result = score_df.copy()\n",
    "    result[\"availability_score\"] = scores\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming HCK_HEC_STAFFING is already loaded\n",
    "staffing_inverted = invert_availability_values(df_staffing)\n",
    "score_df_Data_Engineer = add_availability_score_to_users(staffing_inverted, selected_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Cosine similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Nehal\\JSON Embedding and Matching\\OUTPUTS\\user_similarity_ranking.csv\"\n",
    "\n",
    "# Step 1: Read just the column names to check if 'user_rank' exists\n",
    "columns_to_read = pd.read_csv(file_path, nrows=0).columns.tolist()\n",
    "\n",
    "# Step 2: Remove 'user_rank' if it exists\n",
    "if 'user_rank' in columns_to_read:\n",
    "    columns_to_read.remove('user_rank')\n",
    "\n",
    "# Step 3: Read the CSV again, excluding 'user_rank' if present\n",
    "sim_df = pd.read_csv(file_path, usecols=columns_to_read)\n",
    "\n",
    "# Convert similarity_score to percentage (0-100)\n",
    "sim_df['similarity_score'] = sim_df['similarity_score'].apply(lambda x: round(x * 100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Experience Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "Users_Lang_Skills = pd.read_csv(r'C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Pivot Processing\\Output\\Users_Lang_Skills.csv')\n",
    "\n",
    "def add_extracted_experience_score_to_users(score_df: pd.DataFrame, selected_job: str) -> pd.DataFrame:\n",
    "    Users_Lang_Skills = pd.read_csv(r'C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Ashraf\\Pivot Processing\\Output\\Users_Lang_Skills.csv')\n",
    "    \"\"\"\n",
    "    Adds an 'experience_score' column to score_df based on the experience required\n",
    "    for the selected job, loaded from a JSON features file.\n",
    "\n",
    "    The scoring is binned:\n",
    "        - â‰¥ required + 2 years â†’ 100\n",
    "        - > required + 2 to 4 â†’ 70\n",
    "        - > required + 4       â†’ 50\n",
    "        - == required          â†’ 100\n",
    "        - < required by â‰¤ 2    â†’ 50\n",
    "        - < required by 2â€“4    â†’ 30\n",
    "        - < required by >4     â†’ 10\n",
    "        - Missing experience   â†’ 0\n",
    "    \"\"\"\n",
    "    os.chdir(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Job_description_features\")\n",
    "    # === Step 1: Load job features JSON ===\n",
    "    file_path = f\"{selected_job.replace(' ', '_')}_features.json\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            features = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"No JSON file found for job '{selected_job}'\")\n",
    "\n",
    "    required_exp = features.get(\"Experience Required\", 0)\n",
    "\n",
    "    df = score_df.copy()\n",
    "\n",
    "    def calculate_score(user_exp):\n",
    "        if pd.isna(user_exp):\n",
    "            return 0\n",
    "        delta = user_exp - required_exp\n",
    "        if delta >= 2:\n",
    "            return 100\n",
    "        elif 0 <= delta < 2:\n",
    "            return 100\n",
    "        elif -2 < delta < 0:\n",
    "            return 50\n",
    "        elif -4 < delta <= -2:\n",
    "            return 30\n",
    "        elif delta <= -4:\n",
    "            return 10\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Map score using ANNEES_XP from Users_Lang_Skills\n",
    "    experience_series = Users_Lang_Skills.set_index(\"USER_ID\")[\"ANNEES_XP\"]\n",
    "    df = df.set_index(\"USER_ID\")\n",
    "    df[\"experience_score\"] = experience_series.reindex(df.index).apply(calculate_score).fillna(0)\n",
    "\n",
    "    return df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then add experience scores from JSON\n",
    "score_df = add_extracted_experience_score_to_users(base_df, selected_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Unmatched Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Assuming your DataFrame is named 'df'\n",
    "columns = data_analyst_df.columns\n",
    "list1 = [col.replace('req_', '').replace('_score', '').lower() for col in columns if col.startswith('req_')]\n",
    "list2 = [col.replace('pref_', '').replace('_score', '').lower() for col in columns if col.startswith('pref_')]\n",
    "weights_list = ['weight_required_skills', 'weight_preferred_skills','weight_language']\n",
    "lang_list = [col for col in columns if col.startswith('lang_')] + ['weight_language']\n",
    "exclude_columns_base = ['USER_ID','LAST_NAME','FIRST_NAME','ANNEES_XP','English_level','French_level']\n",
    "unmatched_skills_cols =  [col for col in base_df.columns if col not in list1 + list2 + lang_list + weights_list + exclude_columns_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_20068\\3857539597.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unmatched_df['unmatched_skills_score'] = unmatched_df[columns_to_average].sum(axis=1) / len(columns_to_average)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_20068\\3857539597.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unmatched_df['unmatched_skills_score'] = unmatched_df['unmatched_skills_score'].round(1)\n"
     ]
    }
   ],
   "source": [
    "exclude_columns_1 = ['USER_ID']\n",
    "unmatched_df = base_df[exclude_columns_1 + unmatched_skills_cols]\n",
    "# Get all columns except excluded ones\n",
    "columns_to_average = [col for col in unmatched_df.columns \n",
    "                     if col not in exclude_columns_1]\n",
    "\n",
    "# Calculate average score (sum of remaining columns divided by count)\n",
    "unmatched_df['unmatched_skills_score'] = unmatched_df[columns_to_average].sum(axis=1) / len(columns_to_average)\n",
    "\n",
    "# Optional: Round to 2 decimal places\n",
    "unmatched_df['unmatched_skills_score'] = unmatched_df['unmatched_skills_score'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join availability_score first\n",
    "data_analyst_df = pd.merge(\n",
    "    data_analyst_df,\n",
    "    score_df_Data_Engineer[['USER_ID', 'availability_score']],\n",
    "    on='USER_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Then join similarity_score\n",
    "data_analyst_df = pd.merge(\n",
    "    data_analyst_df,\n",
    "    sim_df[['USER_ID', 'similarity_score']],\n",
    "    on='USER_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Finally join unmatched_skills_score\n",
    "data_analyst_df = pd.merge(\n",
    "    data_analyst_df,\n",
    "    unmatched_df[['USER_ID', 'unmatched_skills_score']],\n",
    "    on='USER_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Finally join experience_score\n",
    "data_analyst_df = pd.merge(\n",
    "    data_analyst_df,\n",
    "    score_df[['USER_ID', 'experience_score']],\n",
    "    on='USER_ID',\n",
    "    how='left'\n",
    ")\n",
    "data_analyst_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating final Normalized score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adaptive_weights(df):\n",
    "    \"\"\"Dynamic weights with new base distribution and conditional adjustments\"\"\"\n",
    "    # Base weights (total = 0.65)\n",
    "    base_weights = {\n",
    "        'normalized_lang_score': 0.20,    # Language\n",
    "        'experience_score': 0.25,         # Experience (new higher weight)\n",
    "        'similarity_score': 0.15,         # Similarity\n",
    "        'availability_score': 0.05        # Availability\n",
    "    }\n",
    "    \n",
    "    # Skill weights (total = 0.35)\n",
    "    skill_weights = {\n",
    "        'normalized_req_score': 0.25,     # Required skills\n",
    "        'normalized_pref_score': 0.10     # Preferred skills\n",
    "    }\n",
    "    \n",
    "    # Detect available columns\n",
    "    req_exists = 'normalized_req_score' in df.columns\n",
    "    pref_exists = any(col.startswith('pref_') and col.endswith('_score') \n",
    "                     for col in df.columns)\n",
    "    \n",
    "    # Case 1: Both skill types exist\n",
    "    if req_exists and pref_exists:\n",
    "        weights = {**base_weights, **skill_weights}\n",
    "    \n",
    "    # Case 2: Only required skills exist\n",
    "    elif req_exists and not pref_exists:\n",
    "        weights = {**base_weights, 'normalized_req_score': 0.35}\n",
    "    \n",
    "    # Case 3: Only preferred skills exist (unlikely)\n",
    "    elif pref_exists and not req_exists:\n",
    "        weights = {**base_weights, 'normalized_pref_score': 0.35}\n",
    "    \n",
    "    # Case 4: No skill columns - redistribute\n",
    "    else:\n",
    "        weights = base_weights.copy()\n",
    "        # Redistribute skill weight proportionally to base weights\n",
    "        total_base = sum(base_weights.values())\n",
    "        for k in weights:\n",
    "            weights[k] += (0.35 * (base_weights[k]/total_base))\n",
    "    \n",
    "    # Final validation\n",
    "    total = sum(weights.values())\n",
    "    assert abs(total - 1.0) < 0.001, f\"Invalid weight sum: {total}\"\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Calculate weights\n",
    "adaptive_weights = calculate_adaptive_weights(data_analyst_df)\n",
    "\n",
    "# Calculate candidate score (with safe column access)\n",
    "score_components = {\n",
    "    col: data_analyst_df[col] * weight \n",
    "    for col, weight in adaptive_weights.items() \n",
    "    if col in data_analyst_df.columns\n",
    "}\n",
    "\n",
    "data_analyst_df['Candidate_score'] = (\n",
    "    sum(score_components.values())\n",
    ").round(2)\n",
    "\n",
    "# Show results\n",
    "# print(\"Applied weights:\", {k: round(v, 3) for k, v in adaptive_weights.items()})\n",
    "result_cols = ['USER_ID', 'Candidate_score'] + list(adaptive_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied weights: {'normalized_lang_score': 0.2, 'experience_score': 0.25, 'similarity_score': 0.15, 'availability_score': 0.05, 'normalized_req_score': 0.25, 'normalized_pref_score': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Applied weights:\", {k: round(v, 3) for k, v in adaptive_weights.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df.sort_values(by='Candidate_score', ascending=False, inplace=True)\n",
    "data_analyst_df = data_analyst_df[data_analyst_df['availability_score'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the final file with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved candidate scores for Data Engineer to:\n",
      "C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\\candidates_scores_data_engineer.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Save with dynamic filename\n",
    "output_dir = r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\"\n",
    "filename = f\"candidates_scores_{selected_job.lower().replace(' ', '_')}.csv\"\n",
    "output_path = Path(output_dir) / filename\n",
    "\n",
    "data_analyst_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved candidate scores for {selected_job} to:\\n{output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df1 = pd.read_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\\candidates_scores_scrum_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>Candidate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433136</td>\n",
       "      <td>70.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2676328</td>\n",
       "      <td>64.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2579999</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2540340</td>\n",
       "      <td>60.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2551856</td>\n",
       "      <td>58.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  Candidate_score\n",
       "0  2433136            70.36\n",
       "1  2676328            64.89\n",
       "2  2579999            61.00\n",
       "3  2540340            60.22\n",
       "4  2551856            58.04"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst_df1[['USER_ID', 'Candidate_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df2 = pd.read_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\\candidates_scores_data_engineer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>Candidate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433111</td>\n",
       "      <td>55.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2551856</td>\n",
       "      <td>55.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2445149</td>\n",
       "      <td>54.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2433112</td>\n",
       "      <td>54.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2447746</td>\n",
       "      <td>53.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  Candidate_score\n",
       "0  2433111            55.84\n",
       "1  2551856            55.21\n",
       "2  2445149            54.79\n",
       "3  2433112            54.75\n",
       "4  2447746            53.73"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst_df2[['USER_ID', 'Candidate_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df2['Demand_id'] = 'Data Engineer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df1['Demand_id'] = 'Scrum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df3 = pd.read_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\\candidates_scores_data_engineer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df3 = data_analyst_df3[['USER_ID','Candidate_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>Candidate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433111</td>\n",
       "      <td>55.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2551856</td>\n",
       "      <td>55.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2445149</td>\n",
       "      <td>54.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2433112</td>\n",
       "      <td>54.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2447746</td>\n",
       "      <td>53.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  Candidate_score\n",
       "0  2433111            55.84\n",
       "1  2551856            55.21\n",
       "2  2445149            54.79\n",
       "3  2433112            54.75\n",
       "4  2447746            53.73"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>dax</th>\n",
       "      <th>databricks lakehouse platform</th>\n",
       "      <th>microsoft power bi</th>\n",
       "      <th>sql</th>\n",
       "      <th>snowflake data cloud</th>\n",
       "      <th>English_level</th>\n",
       "      <th>French_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2447746</td>\n",
       "      <td>Payne</td>\n",
       "      <td>Paul</td>\n",
       "      <td>2.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USER_ID LAST_NAME FIRST_NAME  ANNEES_XP   dax  \\\n",
       "14  2447746     Payne       Paul        2.5  70.0   \n",
       "\n",
       "    databricks lakehouse platform  microsoft power bi   sql  \\\n",
       "14                           60.0               100.0  70.0   \n",
       "\n",
       "    snowflake data cloud  English_level  French_level  \n",
       "14                  80.0           70.0         100.0  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for the specific user\n",
    "user_row = base_df[base_df['USER_ID'] == 2447746]\n",
    "\n",
    "# Select columns where value is not 0 (for numeric columns)\n",
    "non_zero_cols = user_row.loc[:, (user_row != 0).any(axis=0)]\n",
    "\n",
    "# Display the result\n",
    "non_zero_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_df3 = data_analyst_df3[['USER_ID','Candidate_score']]\n",
    "data_analyst_df3['Demand_id'] = 'Data Analyst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data_analyst_df1[['Demand_id','USER_ID','Candidate_score']].head(5),data_analyst_df2[['Demand_id','USER_ID','Candidate_score']].head(5),data_analyst_df3[['Demand_id','USER_ID','Candidate_score']].head(5)]).to_csv(r\"C:\\Users\\hp\\Documents\\GitHub\\HEC_DS_Challenge\\Datasets\\Outputs\\Final-output\\candidates_scores.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>weight_required_skills</th>\n",
       "      <th>weight_preferred_skills</th>\n",
       "      <th>weight_language</th>\n",
       "      <th>req_R_score</th>\n",
       "      <th>req_Atlassian JIRA Software_score</th>\n",
       "      <th>req_Microsoft Power BI_score</th>\n",
       "      <th>lang_French_score</th>\n",
       "      <th>lang_English_score</th>\n",
       "      <th>normalized_lang_score</th>\n",
       "      <th>normalized_req_score</th>\n",
       "      <th>normalized_pref_score</th>\n",
       "      <th>availability_score</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>unmatched_skills_score</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>Candidate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433136</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>50</td>\n",
       "      <td>70.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2676328</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>160.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>50</td>\n",
       "      <td>64.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2579999</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>50</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2540340</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>50</td>\n",
       "      <td>60.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2551856</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>83.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>50</td>\n",
       "      <td>58.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  weight_required_skills  weight_preferred_skills  weight_language  \\\n",
       "0  2433136                       9                        0                5   \n",
       "1  2676328                       9                        0                5   \n",
       "2  2579999                       9                        0                5   \n",
       "3  2540340                       9                        0                5   \n",
       "4  2551856                       9                        0                5   \n",
       "\n",
       "   req_R_score  req_Atlassian JIRA Software_score  \\\n",
       "0        200.0                              200.0   \n",
       "1        160.0                              200.0   \n",
       "2         80.0                              160.0   \n",
       "3         40.0                              100.0   \n",
       "4         80.0                                0.0   \n",
       "\n",
       "   req_Microsoft Power BI_score  lang_French_score  lang_English_score  \\\n",
       "0                         200.0              300.0               200.0   \n",
       "1                         180.0              300.0               180.0   \n",
       "2                         200.0              300.0               200.0   \n",
       "3                         120.0              300.0               140.0   \n",
       "4                         200.0              300.0               160.0   \n",
       "\n",
       "   normalized_lang_score  normalized_req_score  normalized_pref_score  \\\n",
       "0                  100.0                  66.7                    0.0   \n",
       "1                   96.0                  60.0                    0.0   \n",
       "2                  100.0                  48.9                    0.0   \n",
       "3                   88.0                  28.9                    0.0   \n",
       "4                   92.0                  31.1                    0.0   \n",
       "\n",
       "   availability_score  similarity_score  unmatched_skills_score  \\\n",
       "0                75.0              71.8                     6.1   \n",
       "1                50.0              64.6                     9.6   \n",
       "2                75.0              50.9                    11.8   \n",
       "3               100.0             100.0                     4.4   \n",
       "4                75.0              83.4                     8.2   \n",
       "\n",
       "   experience_score  Candidate_score  \n",
       "0                50            70.36  \n",
       "1                50            64.89  \n",
       "2                50            61.00  \n",
       "3                50            60.22  \n",
       "4                50            58.04  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjob_data\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'job_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>dax</th>\n",
       "      <th>microsoft power bi</th>\n",
       "      <th>microsoft sql server</th>\n",
       "      <th>sql</th>\n",
       "      <th>snowflake data cloud</th>\n",
       "      <th>tableau desktop and online</th>\n",
       "      <th>English_level</th>\n",
       "      <th>French_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2433111</td>\n",
       "      <td>Richards</td>\n",
       "      <td>William</td>\n",
       "      <td>2.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USER_ID LAST_NAME FIRST_NAME  ANNEES_XP   dax  microsoft power bi  \\\n",
       "79  2433111  Richards    William        2.5  70.0                80.0   \n",
       "\n",
       "    microsoft sql server    sql  snowflake data cloud  \\\n",
       "79                  80.0  100.0                  90.0   \n",
       "\n",
       "    tableau desktop and online  English_level  French_level  \n",
       "79                        70.0          100.0         100.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
