{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Reading files from OCR"
      ],
      "metadata": {
        "id": "LIWB_ZAWw21r"
      }
    },
    {
      "source": [
        "!pip install pymupdf\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr-fra\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract' # Set the path to your tesseract executable"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQJ6ekHfvwwj",
        "outputId": "4eeda1c9-37f0-4cf7-afc8-fac173e8c3b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.4\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,703 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.3 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 2s (2,333 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126256 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pytesseract"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Iw9Ql0WLvxZa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "#Import the Image module from PIL\n",
        "\n",
        "def ocr_pdf(pdf_path, language='eng'):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file using OCR.\n",
        "\n",
        "    Args:\n",
        "    pdf_path: Path to the PDF file.\n",
        "    language: Language of the text ('eng' for English, 'fra' for French).\n",
        "\n",
        "    Returns:\n",
        "    Extracted text as a string.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = ''\n",
        "    for page in doc:\n",
        "        pix = page.get_pixmap()\n",
        "        # Create a PIL Image object from the pixmap bytes\n",
        "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "        text += pytesseract.image_to_string(img, lang=language)\n",
        "    return text"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BECADrlyvxzz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "source": [
        "pdf_file = '/content/Scrum.pdf'  # Replace with your PDF file path\n",
        "extracted_text = ocr_pdf(pdf_file, language='fra')  # Use 'fra' for French\n",
        "print(extracted_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LluzPxdSvyVK",
        "outputId": "c69dbb2d-3ddd-48ec-c92e-54be758a1095"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scrum Master- Contrat de 12 mois\n",
            "\n",
            " \n",
            "\n",
            "Lieu : Montréal\n",
            "Date de démarrage : Dès que possible\n",
            "Durée : 12 mois, avec possibilité de renouvellement\n",
            "\n",
            "Dans Le cadre d'un mandat d'importance stratégique, nous recherchons un(e) Serum\n",
            "Master expérimenté(e) pour guider une équipe Agile multidisciplnaire au sein d'un\n",
            "environnement stimulant et en pleine transformation numérique.\n",
            "\n",
            "Nom de l'entreprise : Alimora Groupe\n",
            "\n",
            "Stogan : Cuttiver l'avenir, nourri l'excellence\n",
            "\n",
            " \n",
            "\n",
            "Présentation de l'entreprise\n",
            "\n",
            "Fondé en 1998, Alimora Groupe est un acteur majeur de l'agroalimentaire durable en\n",
            "Amérique du Nord. Spécialisé dans la production, la transformation et a distribution de\n",
            "produits alimentaires de qualité, Le groupe s'engage à offrir une alimentation saine et\n",
            "accessible, tout en respectant l'environnement et les communautés Locales.\n",
            "\n",
            "Avec plus de 1 500 employés répartis sur 7 sites de production et une présence dans plus\n",
            "de 12 pays, Alimora se distingue par Son innovation constante, son excellence\n",
            "‘opérationnelle et sa capacité à anticiper les tendances de consommation.\n",
            "\n",
            "Domaines d'expertise :\n",
            "+ _ Transformation de produits frais (fruits, légumes, protéines végétales)\n",
            "+ Production bio et circuits courts\n",
            "+\" Recherche & Développement en nutrition durable\n",
            "+ Logistique intégrée et chaine du froïd\n",
            "\n",
            "+ Développement de produits à marque privée (MDD)\n",
            "\fRôle etresponsabilités\n",
            "\n",
            "Entant que Serum Master, vous jousrez un rôle clé dans le pilotage de l'agilité\n",
            "\n",
            "opérationnelle d'une équipe, en favorisant l'atteinte des objectifs d'affaires tout en\n",
            "\n",
            "renforçant la collaboration, la transparence et l'amélioration continue. Vos responsabilités\n",
            "\n",
            "incluent notamment\n",
            "\n",
            "Mettre en place et maintenir un cadre Agile efficace propice à La performance\n",
            "collective.\n",
            "\n",
            "Facliter l'ensemble des cérémonies Scrum (Daily Scrum, Sprint Planning, Sprint\n",
            "Review, Rétrospective, Refinement}\n",
            "\n",
            "Assurer une gestion proactive des obstacles, afin de garantir Le bon déroulement\n",
            "des livrables.\n",
            "\n",
            "Accompagner l'équipe dans le développement de son autonomie et de sa\n",
            "capacité d'auto-organisation.\n",
            "\n",
            "AAgiren tant que coach Agile, on guidant l'équipe etles parties prenantes dans La\n",
            "{compréhension et l'application des valeurs, principes et pratiques agiles.\n",
            "\n",
            "Promouvoir une eulture de collaboration et d'amélioration continue.\n",
            "\n",
            "Aider le Product Owner à gérer efficacement le backlog produit, à définir Les\n",
            "priorités et à maximiser La valeur livrée.\n",
            "\n",
            "Mesurer et analyser La performance de l'équipe via des indicateurs clés (vélocité,\n",
            "burndown charts, lead time, etc), en utilisant des outils adaptés.\n",
            "\n",
            "Protéger l'équipe des interférences externes et veiller à maintenir un climat de\n",
            "travail serein.\n",
            "\n",
            "Environnement technologique et outils utilisés\n",
            "\n",
            "Outits de gestion Agile : ira, Confluence\n",
            "{Communication et collaboration : Microsoft Teams, Slack, Miro\n",
            "\n",
            "Tableaux de bord et métriques : ira Dashboard, Pouver BI, Excel avancé\n",
            "Méthodologies : Serum, Kanban, SAFe (atout Lean\n",
            "\n",
            "Langues : Français (sssentiel, Anglais (fonctionnel)\n",
            "\fProfil recherché\n",
            "\n",
            "+ Minimum 3 ans d'\n",
            "fort enjeu:\n",
            "\n",
            " \n",
            "\n",
            "expérience en tant que Scrum Master dans un contexte Agile à\n",
            "\n",
            "+ Solide compréhension des cadres méthodologiques Agiles (Scrum, Kanban, Lean)\n",
            "et capacité à adapter les pratiques au contexte de l'équipe.\n",
            "\n",
            "+ _ Excellentes compétences interpersonnelles : leadership, diplomatie, capacité\n",
            "d'influence.\n",
            "\n",
            "+. Fortespri d'analyse et capacité à traduire les problématiques en actions\n",
            "concrètes\n",
            "\n",
            "+. Expérience dans un contexte hybride ou multi-équipes est un atout\n",
            "\n",
            "Ce mandat vous permettra de contribuer activement à La réussite d'une équipe Agile\n",
            "“engagée, out en évoluant dans un environnement propice à la transformation\n",
            "numérique et à l'innovation.\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "source": [
        "pdf_file = '/content/Data Engineer.pdf'  # Replace with your PDF file path\n",
        "extracted_text = ocr_pdf(pdf_file, language='fra')  # Use 'fra' for French\n",
        "print(extracted_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQBluisrwQVq",
        "outputId": "eeba1a4b-5f49-4989-fa3a-870a0291447b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "Poste: Data Enginoer\n",
            "+ Type de contrat: Contrat\n",
            "+\" Date de début: Dès que possible\n",
            "+ Durée du mandat: 12mois\n",
            "\n",
            "+. Date limite de dépôt: 6 novembre à 14h\n",
            "\n",
            "Apropos de\n",
            "\n",
            " \n",
            "\n",
            "ntreprise\n",
            "\n",
            "RetailNova ost un Leader du secteur du commerce de détail, avec un réseau de\n",
            "distribution omnicanal présent à travers tout Le territoire. L'entreprise combine innovation\n",
            "technologique et excellence opérationnelle pour optimiser ses processus, anticiper Les\n",
            "besoins des clients et maximiser la performance. Dans Le cadre de sa stratégie de\n",
            "transformation numérique, RetailNova investit massivement dans La modernisation de ses.\n",
            "infrastructures de données pour accélérer a prise de décision fondée sur des analyses\n",
            "\n",
            "Contexte du mandat :\n",
            "\n",
            "RetailNova met en œuvre une nouvelle plateforme d'entreprise basée sur des technologies\n",
            "cloud afin de centraliser, sécuriser et valoriser ses données opérationnelles,\n",
            "transactionnelles et clients. Ce projet stratégique vise à moderniser l'écosystème\n",
            "analytique, à automatiser Les flux de données, à améliorer la gouvernance, et à renforcer La\n",
            "qualité et la traçabilité des données à l'échelle de l'entreprise.\n",
            "\n",
            "Le Data Engineer sera responsable de la conception, du développement, de l'optimisation\n",
            "t du déploiement des pipelines de données nécessaires à l'alimentation du data lake\n",
            "d'entreprise. Linterviendra également dans La mise en place de nouvelles architectures de\n",
            "traitement en temps réel, en assurant la robustesse, La scalabiité etla performance des\n",
            "solutions déployées.\n",
            "\n",
            "Responsabilités détaillées :\n",
            "\n",
            " \n",
            "\n",
            "+ Concevoir et développer des pipelines\n",
            "optimisés à l'aide d'Azure Data Factory pour intégrer des données provenant de\n",
            "sources muttiptes (ERP, CRM, POS, e-commerce, etc.\n",
            "\n",
            "ingestion de données robustes et\n",
            "\fDévelopper des transformations complexes en utilisant Apache Spark\n",
            "(Scala/Python) dans Azure Databricks, avec une forte orientation performance et\n",
            "optimisation des coûts.\n",
            "\n",
            "Implémenter des flux de données streaming et batch via Databricks Streaming et\n",
            "Apache Kafka, en assurant une faible latence et une haute disponibilité.\n",
            "\n",
            "Participer à la définition et à La mise en œuvre de modèles de données adaptés aux\n",
            "besoins analytiques (data marts, data lakehouse).\n",
            "\n",
            "Mettre en œuvre des processus de validation de La qualité des données (data\n",
            "quality checks, data profiing, monitoring automatisé),\n",
            "\n",
            "Automatiser les déploiements et Les tests des pipelines via Azure DevOps (CI/CD,\n",
            "versioning, rollback\n",
            "\n",
            "Documenter es solutions développées selon Les normes internes, et assurer La\n",
            "traçabilité etla réplicabilité des traitements.\n",
            "\n",
            "Travailler en collaboration avec Les équipes Data Science, Bl et T Infrastructure\n",
            "pour garantir l'alignement des livrables avec Les objectifs stratégiques.\n",
            "\n",
            "Participer à l'élaboration de normes et de standards d'ingénierie des données à\n",
            "l'échelle de l'organisation.\n",
            "\n",
            "Compétences techniques requises :\n",
            "\n",
            "8+ ans d'expérience en développement d'applications de traitement de données\n",
            "distribuées avec Apache Spark (obligatoire),\n",
            "\n",
            "Solide maitrise de Python et Scala pour le développement de traitements de\n",
            "données volumineuses.\n",
            "\n",
            "Expérience significative avec Azure Data Factory, Azure Data Lake Storage (Gen2),\n",
            "et Azure Databricks.\n",
            "\n",
            "Connaissance approfondie de Kafka (installation, configuration, gestion des topics,\n",
            "Sécurité, monitoring).\n",
            "\n",
            "Maitrise des principes d'architecture data : partitionnement, indexation,\n",
            "optimisation des formats (Parquet, Delta Lake), gestion des métadonnées.\n",
            "\n",
            "Expérience avec Les outils de gestion des flux CI/CD dans Azure DevOps\n",
            "{pipelines, artefacts, gestion de configuration)\n",
            "\f+ Connaissance des principes de gouvernance des données, de catalogage (ex.\n",
            "Azure Purview), et des bonnes pratiques de sécurité (RBAC, encryption, masking).\n",
            "\n",
            "+ Capacité à concevoir des modèles de données analytiques (Kimball, Data Vault)\n",
            "t à travailler avec des entrepôts de données (ex. Synapse Analytics),\n",
            "\n",
            "Atouts :\n",
            "+ Expérience dans des environnements retail ou grande distribution [gestion des\n",
            "données transactionnelles, gestion de La Supply chain, etc\n",
            "+ Expérience avec des outils de monitoring des pipelines {ex : Azure Monitor, Log\n",
            "Analytics, Datadog).\n",
            "\n",
            " \n",
            "\n",
            "+ Connaissances de base en Data Science/Machine Learning pour interagir avec Les\n",
            "\n",
            "équipes concernées.\n",
            "\n",
            "Compétences interpersonnelles :\n",
            "+. Forte capacité à résoudre des problèmes complexes de manière autonome.\n",
            "\n",
            "+ Rigueur et attention aux détails, particulièrement dans Les aspects liés à La qualité\n",
            "la fiabilité des données.\n",
            "\n",
            "+ Compétences en communication technique, capacité à documenter et présenter\n",
            "des solutions techniques à divers niveaux d'interlocuteurs.\n",
            "\n",
            "+. Esprit d'équipe, ouverture au partage de connaissances et participation active à\n",
            "l'amélioration continue.\n",
            "\n",
            "Langues :\n",
            "\n",
            "+. Français et anglais: maîtrise professionnelle complète, tant à l'oral qu'à l'écrit\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "source": [
        "pdf_file = '/content/Data Analyst.pdf'  # Replace with your PDF file path\n",
        "extracted_text = ocr_pdf(pdf_file, language='fra')  # Use 'fra' for French\n",
        "print(extracted_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEQyuutXwXsy",
        "outputId": "00f48034-63d3-46e0-c0ae-cbdac9f3314b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profil\n",
            "\n",
            "Data Analyst - Marketing Analytics.\n",
            "\n",
            "A propos de Veltrida\n",
            "\n",
            "Vettrixia Technologies Inc. estune entreprise spécialisée dans Les solutions de données\n",
            "etlinteligence marketing. Basé à Montréal, Veltrixia accompagne depuis plus de 15 ans\n",
            "des entreprises nord-américaines dans l'optimisation de leurs performances grâce à des\n",
            "technologies analytiques avancées. L'entreprise mise sur l'innovation, la collaboration et\n",
            "l'excellence pour propulser ses clients vers Le futur numérique.\n",
            "\n",
            "Contexte\n",
            "\n",
            "Dans Le cadre du développement de notre équipe analytique marketing, nous recherchons\n",
            "une analyste de données pour travailler sur des projets liés à la collecte, l'analyse etla\n",
            "visualisation de données marketing. Vous serez responsable de la maintenance et de\n",
            "L'évolution de jeux de données provenant de sources variées, afin de soutenir Les équipes\n",
            "dans leur prise de décision basée sur Les données.\n",
            "\n",
            " \n",
            "\n",
            "Détails du poste\n",
            "+. Durée : 10 mois (renouvelable)\n",
            "+ Type: Temps plein\n",
            "\n",
            "+\" Mode de travai : Hybride (2 jours par semaine au bureau à Montréal)\n",
            "\n",
            "Responsabilités principales\n",
            "+\" Gérer et améliorerLes jeux de données marketing.\n",
            "+\" Développer des tableaux de bord et rapports dans Power BL\n",
            "+\" Optimiserles porformances des datasets Power BI.\n",
            "\n",
            "+ _ Intégrer les données issues de diverses plateformes (Google Analytics, CRM, outils\n",
            "marketing)\n",
            "\n",
            "+. Rédiger du code SQL, DAX et Power Query performant.\n",
            "\fGollaborer étroitement avec Les anatystes pour comprendre Leurs besains.\n",
            "Gréer des requêtes dans Databricks et SSMS.\n",
            "\n",
            "Assurer a qualité et a fiabilité des données.\n",
            "\n",
            "Soutenir les callègues via des revues de cade et du support technique.\n",
            "\n",
            "Concevoir des modèles de données adaptés aux objectifs métiers.\n",
            "\n",
            "Profil recherché\n",
            "\n",
            "Compétences techniques\n",
            "\n",
            "Minimum 8 ans d'expérionce en analyse de données.\n",
            "Solide maitrise de SQL (MS SQL Server, Power Bi, Databricks.\n",
            "Expérionce avec DAX, Power Query, ETL.\n",
            "\n",
            "Connaissance des données marketing, un atout.\n",
            "\n",
            "Capacité à modéliser Les données et à optimiser les processus.\n",
            "\n",
            "Compétences personnelles\n",
            "\n",
            "Curieuxse, autonome, rigoureux se.\n",
            "Bonne gestion du temps et esprit d'équipe.\n",
            "\n",
            "Excellente capacité d'analyse et de résolution de problèmes.\n",
            "\n",
            "Langues\n",
            "\n",
            "Maitrise de l'anglais et du français.\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "begypYc-wEDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}